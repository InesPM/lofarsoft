/***************************************************************************
 *   Copyright (C) 2007                                                    *
 *   Lars B"ahren (bahren@astron.nl)                                       *
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 *   This program is distributed in the hope that it will be useful,       *
 *   but WITHOUT ANY WARRANTY; without even the implied warranty of        *
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         *
 *   GNU General Public License for more details.                          *
 *                                                                         *
 *   You should have received a copy of the GNU General Public License     *
 *   along with this program; if not, write to the                         *
 *   Free Software Foundation, Inc.,                                       *
 *   59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.             *
 ***************************************************************************/

// ==============================================================================
//
//  Main page of the Doxygen documentation
//
// ==============================================================================

/*!
  \mainpage LOFAR User Software

  More LOFAR documentation:

  <ul>
    <li>The <a href="http://www.astron.nl/radio-observatory/lofar/lofar-imaging-cookbook">LOFAR imaging cookbook</a> was initially  written by Timothy Garn, who was its main author till his death in 2009. Currently, Roberto Pizzo is in charge of udating it thanks to the contributions of the Lofar commissioners.  The manual explains how to manually reduce imaging data and inspect the results, using tools from the standard imaging pipeline (NDPPP, BBS, and MWImager). 

    <li><a href="http://www.astron.nl/radio-observatory/astronomers/lofar-beamformed-data-pipeline-cookbook/lofar-beamformed-data-pipeline">LOFAR Beamformed-Data Pipeline Cookbook</a>

    <li><a href="http://usg.lofar.org/documentation/pipeline">LOFAR pipeline
    system</a>: This system has largely been developed to support the LOFAR
    imaging pipeline, but is now being deployed for a variety of science pipelines
    on the LOFAR cluster. This document is split into three sections: the first
    describes the aims of the framework, the structure of a pipeline, and gives
    an overview of how the system fits together, as well as information on how to
    run pre-defined pipelines. The second provides a tutorial introduction to
    writing pipelines and pipeline components. The third describes the framework
    codebase in more detail, and is intended for pipeline authors who wish to dig
    a little deeper, as well as those interested in developing the framework   
    itself. The fourth provides a guide to the imaging pipeline itself.
  </ul>
  
*/

// ==============================================================================
//
//  Definition of groups
//
// ==============================================================================

//_______________________________________________________________________________
//                                                                        contrib

/*!
  \defgroup contrib Collection of user contributed code
	
  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      |-- contrib        <-- you are here
      |   |-- shapelets
      |   |-- testing
      |   `-- utilities
      |-- CR-Tools
      |-- DAL
      `-- BDSM
  \endverbatim
*/

//_______________________________________________________________________________
//                                                                       pipeline

/*!
  \defgroup pipeline Pipeline-Framework
	
  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      |-- pipeline       <-- you are here
      |   |-- deploy
      |   |-- doc
      |   |-- examples
      |   |-- mac
      |   |-- pipeline
      |   `-- recipes
      |-- CR-Tools
      |-- DAL
      `-- BDSM
  \endverbatim	
  
  The framework aims to make it possible to manage a variety of different
  processing steps in a flexible yet consistent way, while running them in
  parallel across the LOFAR offline cluster.

  <h4>Cluster Layout</h4>

  The pipeline framework makes the assumption that it will run on a cluster
  comprised of a "head node" and a number of "compute nodes". The pipeline
  control logic runs on the head node, and may perform less compute-intensive
  jobs here. When required, jobs are dispatched over the network to the compute
  nodes: the head node may then wait and receive the results before continuing.
  Job definition and parameters may be pushed to the compute nodes directly from
  the head using <a href="http://ipython.scipy.org">IPython</a>; however, for
  bandwidth and latency reasons, large data files should be written to and read
  from shared NFS mounts.

  <h4>Recipes</h4>

  A \b recipe is a unit of the pipeline. It consists of a a task with a given set
  of inputs and outputs. A given recipe may contain calls to subsidiary recipes,
  for which it will provide the inputs and use the outputs in its own
  processing. Note that the whole pipeline control structure is itself a recipe:
  it takes a given set of inputs (visibility data) and produces some outputs
  (images and associated metadata) by running through a series of defined steps.
  In fact, each of those steps is itself a recipe -- one for flagging, one for
  calibration, and so on.

  <h4>Control</h4>

  The \b control recipe is a specialist type of a normal recipe. The fundamentals
  are the same; however, it contains some additional "housekeeping" logic which
  may be useful for starting a pipeline. For instance, the control recipe can
  configure a logging system for the pipeline, and may be used to interface with
  LOFAR's MAC/SAS control system.

*/

//_______________________________________________________________________________
//                                                                     Star-Tools

/*!
  \defgroup startools Star-Tools function collection

  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  |   |-- casacore
  |   |-- hdf5
  |   `-- startools   <-- you are here
  `-- src
  \endverbatim
*/

//_______________________________________________________________________________
//                                                                   RM Synthesis

/*!
  \defgroup RM RM-Synthesis package

  \verbatim
  lofarsoft
  |-- data
  |-- doc
  |-- release
  |-- build
  |-- devel_common
  |-- external
  `-- src
      `-- RM                  <-- you are here
          |-- apps
          |-- data
          |-- implement
	  |   |-- rmClean
	  |   |-- rmLib
	  |   `-- rmSim
          `-- test
  \endverbatim

  <h3>External packages</h3>

  - Armadillo
  - IT++
*/

//_______________________________________________________________________________
//                                                                           LASA

/*!
  \defgroup LASA LASA - LOFAR Air-Shower Array

  - \ref lasa_setup
  - \ref lasa_build
  - \ref lasa_commit

  \section lasa_setup Setting up your working copy

  \b Note: This essentially is the  same procedure as already described in the
  \ref configure_build_install.

  <ol>
    <li>For the initial checkout of your working copy run:
    \verbatim
    svn co http://usg.lofar.org/svn/code/trunk lofarsoft
    \endverbatim
    Once the checkout is complete, you will find a new directory \b lofarsoft
    with the following sub-structure:
    \verbatim
    lofarsoft
    |-- data
    |-- doc
    |-- release
    |-- build
    |-- devel_common
    |-- external
    `-- src
        `-- LASA
            |-- analysis
            |-- apps
            |-- implement
	    `-- test
    \endverbatim
    The source code is in \b src/LASA, while the compile and installation is done
    from \b build.

    The individual sub-directores underneath <tt>src/LASA</tt> are used as follows:
    <ul>
      <li>\b implement contains the source files with the classes which are
      compiled into a library (\e liblasa); this library represents the core
      of the algorithm collection. Executables of application programs link
      against this library.
      <li>\b apps holds the source code of application programs, which later can
      be run from the command line.
      <li>\b test collects a number of test programs to test the classes and 
      algorithms within the library.
    </ul>

    <li>Set up your environment: Add the location of the new executables to your
    PATH variable:
    \verbatim
    # csh, tcsh
    setenv LOFARSOFT <root directory of code tree>
    source $LOFARSOFT/devel_common/scripts/init.csh

    # sh, bash
    export LOFARSOFT=<root directory of code tree>
    . $LOFARSOFT/devel_common/scripts/init.sh
    \endverbatim
    If you want this information to be persistent, you should add the setting to
    the configuration file of your shell; for bash users this is done in either
    $HOME/.profile or $HOME/.bashrc â€“ users of tcsh or csh need to add the 
    appropriate statement to $HOME/.cshrc. 
  </ol>

  \section lasa_build Compile the software

  <ol>
    <li>Change into the \b build directory and run the \e bootstrap script:
    \verbatim
    cd build
    ./bootstrap
    \endverbatim
    The major job of the script is to check whether or not a recent version of
    CMake is available on your system; if this is not the case, CMake will be
    build from the provided sources and installed into \b release/bin (which 
    means that of course you should have that directory in your PATH).

    <li>Build the components  of the LASA software package:
    \verbatim
    make lasa
    \endverbatim

    <li>Once the initial build of the package is done -- which also includes
    checking the presence (and if required  build) of external packages, the
    fastest route to build the LASA software while developing and writing new
    code, is by running \e make within the \b build/lasa directory:
    \verbatim
    cd build/lasa
    make
    \endverbatim
  </ol>

  \section lasa_commit Committing changes

  Once  you have made changes to the source code, checking them back into the
  repository works as follows:

  <ol>
    <li>Change into the directory holding the source code:
    \verbatim
    cd src/LASA
    \endverbatim

    <li>Commit the changes by typing
    \verbatim
    svn commit
    \endverbatim
    or
    \verbatim
    svn commit -m "Your short comment about the changes made."
    \endverbatim
    While the first variant will open an editor window for you to type in a
    short commit report, the second variant allows you to directly provide such
    a short statement -- describing what changes were done to the code -- from
    the command line.
  </ol>
*/
